{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0e3cc630a27171bda4963781135d38e3c4b2db62d9414523c30df1024dbff97fb",
   "display_name": "Python 3.8.8 64-bit ('venv': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "e3cc630a27171bda4963781135d38e3c4b2db62d9414523c30df1024dbff97fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "source": [
    "**Improvements**\n",
    "\n",
    "1. More models\n",
    "2. Look at the Kaggle notebooks and take inspo"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Crunch\n",
    "Only run when adding new stuff to cleaner, otherwise use the CSV in the next section"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading original\n",
    "original = pd.read_csv('labeledTrainData.tsv', sep=\"\\t\")\n",
    "original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words(\"english\")\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    words_no_punc = [word.lower() for word in words if word.isalpha()]\n",
    "    no_stop = [word for word in words_no_punc if word not in stops]\n",
    "    stems = [porter.stem(word) for word in no_stop]\n",
    "    clean = ' '.join(stems)\n",
    "\n",
    "    return clean\n",
    "\n",
    "original[\"review_clean\"] = original[\"review\"].apply(lambda text: clean_text(text))\n",
    "original.to_csv('train_clean.csv', index=False)"
   ]
  },
  {
   "source": [
    "# Exploration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_clean.csv', usecols=[\"sentiment\", \"review\", \"review_clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Sentiment: 0\n\nBefore (1127 chars):\nSteve Martin should quit trying to do remakes of classic comedy. He absolutely does not fit this part. Like the woeful remake of the Out Of Towners, this movie falls flat on it's face. How anybody eve\n\nAfter (639 chars):\nsteve martin quit tri remak classic comedi absolut fit part like woeful remak towner movi fall flat face anybodi ever thought steve martin could even come close jack lemmon wonder perform beyond true \n"
     ]
    }
   ],
   "source": [
    "random_nr = random.randint(0, len(df))\n",
    "\n",
    "old = df[\"review\"][random_nr]\n",
    "new = df[\"review_clean\"][random_nr]\n",
    "\n",
    "print(f'Sentiment: {df[\"sentiment\"][random_nr]}')\n",
    "print(f'\\nBefore ({len(old)} chars):')\n",
    "print(old[:200])\n",
    "print(f'\\nAfter ({len(new)} chars):')\n",
    "print(new[:200])"
   ]
  },
  {
   "source": [
    "# Train and test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review_clean'], df['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Logistic regression\n",
    "~88% accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, verbose=2)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Fitting\n",
    "logreg = LogisticRegression(max_iter=1000, verbose=2)\n",
    "\n",
    "logreg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2154,  295],\n",
       "       [ 320, 2231]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "pred_logreg = logreg.predict(X_test)\n",
    "confusion_matrix(pred_logreg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.87      0.88      0.88      2449\n           1       0.88      0.87      0.88      2551\n\n    accuracy                           0.88      5000\n   macro avg       0.88      0.88      0.88      5000\nweighted avg       0.88      0.88      0.88      5000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_logreg, y_test))"
   ]
  },
  {
   "source": [
    "# KNN\n",
    "~63% accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting optimal nr of neighbors (takes ~2 mins)\n",
    "knn_grid = GridSearchCV(\n",
    "    estimator=KNeighborsClassifier(), \n",
    "    param_grid={'n_neighbors': np.arange(3,11)}, # surely not less than 3, 11 as max due to time consumption\n",
    "    verbose=2,\n",
    "    cv=3\n",
    ")\n",
    "knn_grid.fit(X_train, y_train)\n",
    "optimal_neighbors = knn_grid.best_params_['n_neighbors']\n",
    "optimal_neighbors # Will return 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=9) # optimal_neighbors w/o having to run it\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1670, 1040],\n",
       "       [ 804, 1486]])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "pred_knn = knn.predict(X_test)\n",
    "confusion_matrix(pred_knn, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.68      0.62      0.64      2710\n           1       0.59      0.65      0.62      2290\n\n    accuracy                           0.63      5000\n   macro avg       0.63      0.63      0.63      5000\nweighted avg       0.64      0.63      0.63      5000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_knn, y_test))"
   ]
  },
  {
   "source": [
    "# Naive Bayes\n",
    "~65% accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "nb.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2022, 1231],\n",
       "       [ 452, 1295]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "pred_nb = nb.predict(X_test.toarray())\n",
    "confusion_matrix(pred_nb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.82      0.62      0.71      3253\n           1       0.51      0.74      0.61      1747\n\n    accuracy                           0.66      5000\n   macro avg       0.66      0.68      0.66      5000\nweighted avg       0.71      0.66      0.67      5000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_nb, y_test))"
   ]
  },
  {
   "source": [
    "# Random Forest\n",
    "~85% accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=50)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "forest = RandomForestClassifier(max_depth=50, n_estimators=100)\n",
    "\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2059,  322],\n",
       "       [ 415, 2204]])"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "pred_forest = forest.predict(X_test)\n",
    "confusion_matrix(pred_forest, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.83      0.86      0.85      2381\n           1       0.87      0.84      0.86      2619\n\n    accuracy                           0.85      5000\n   macro avg       0.85      0.85      0.85      5000\nweighted avg       0.85      0.85      0.85      5000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_forest, y_test))"
   ]
  },
  {
   "source": [
    "# ANN\n",
    "~87% accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "625/625 - 4s - loss: 0.3561 - accuracy: 0.8562\n",
      "Epoch 2/5\n",
      "625/625 - 3s - loss: 0.1610 - accuracy: 0.9431\n",
      "Epoch 3/5\n",
      "625/625 - 3s - loss: 0.0885 - accuracy: 0.9707\n",
      "Epoch 4/5\n",
      "625/625 - 3s - loss: 0.0525 - accuracy: 0.9844\n",
      "Epoch 5/5\n",
      "625/625 - 4s - loss: 0.0317 - accuracy: 0.9905\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15089b220>"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "ann = Sequential()\n",
    "ann.add(Dense(10, activation = 'relu'))\n",
    "ann.add(Dense(10, activation = 'relu'))\n",
    "ann.add(Dense(1, activation = 'sigmoid'))\n",
    "ann.compile(optimizer = 'Adam', loss ='binary_crossentropy', metrics = ['accuracy'])\n",
    "ann.fit(X_train.toarray(), y_train, batch_size=32, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2177,  363],\n",
       "       [ 297, 2163]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "pred_ann = ann.predict(X_test) > 0.5\n",
    "confusion_matrix(pred_ann, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n       False       0.88      0.86      0.87      2540\n        True       0.86      0.88      0.87      2460\n\n    accuracy                           0.87      5000\n   macro avg       0.87      0.87      0.87      5000\nweighted avg       0.87      0.87      0.87      5000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_ann, y_test))"
   ]
  }
 ]
}